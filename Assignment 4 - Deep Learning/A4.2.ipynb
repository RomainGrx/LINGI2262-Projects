{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1771f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Because it's a tiny dataset, we hide GPUs to use the CPU, it will be faster\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "# gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "# print(gpus)\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    \n",
    "MODEL_PATH = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "((x_train, y_train), (x_test, y_test)) = keras.datasets.fashion_mnist.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee23efa",
   "metadata": {},
   "source": [
    "Question 1 :  A first linear neural network \n",
    "---\n",
    "\n",
    "For this question, we ask you to build and to train a neural network with the following specifications:\n",
    "\n",
    "- The network contains 2 layers:\n",
    "    - A flatten layer which flattens the $28 \\times 28$ 2D images into 1D vectors of size $784$. This layer has no parameter to train, it just reshapes the input data.\n",
    "    - A dense output layer with a softmax activation function such that it can predict the target categorical (=class) variable. The kernel and bias are initializers set to *RandomNormal*.\n",
    "- The network loss is the categorical cross entropy loss.\n",
    "- The network optimizer is the Adam optimizer (an optimized version of the gradient descent procedure) with a learning rate of $10^{-5}$\n",
    "\n",
    "We are here essentially training 10 linear models and then applying a softmax on them. This is **not yet** a deep neural network.\n",
    "\n",
    "Implement your neural network in the variable *model*. Just define and compile the network, don't fit it on the training data (your submission will likely time out if you do!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a28aed9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"linear\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(10, kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\", activation=\"softmax\"),\n",
    "], name=\"linear\")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb81ac",
   "metadata": {},
   "source": [
    "Question 2 : A first linear neural network: model fitting \n",
    "---\n",
    "\n",
    "Fit your model from question 1 on the train data with a batch size of $32$. Run $100$ epochs to fit your model.\n",
    "\n",
    "Once your neural network is fitted, save it in a *.model* file using the [save](https://www.tensorflow.org/guide/keras/save_and_serialize) function of Keras with *save_format='h5'* and upload it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb00fff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 32.5430 - accuracy: 0.5213 - val_loss: 27.4898 - val_accuracy: 0.5737\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 23.9317 - accuracy: 0.6065 - val_loss: 21.8968 - val_accuracy: 0.6300\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 19.7579 - accuracy: 0.6514 - val_loss: 18.9012 - val_accuracy: 0.6617\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 17.3083 - accuracy: 0.6778 - val_loss: 17.0938 - val_accuracy: 0.6820\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 15.7228 - accuracy: 0.6980 - val_loss: 15.8179 - val_accuracy: 0.6965\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 14.5853 - accuracy: 0.7106 - val_loss: 14.9216 - val_accuracy: 0.7068\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 13.7027 - accuracy: 0.7198 - val_loss: 14.1462 - val_accuracy: 0.7132\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 13.0045 - accuracy: 0.7285 - val_loss: 13.6150 - val_accuracy: 0.7209\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 12.4276 - accuracy: 0.7347 - val_loss: 13.0756 - val_accuracy: 0.7253\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 11.9326 - accuracy: 0.7390 - val_loss: 12.6571 - val_accuracy: 0.7300\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 11.5155 - accuracy: 0.7448 - val_loss: 12.2904 - val_accuracy: 0.7344\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 11.1395 - accuracy: 0.7482 - val_loss: 11.9296 - val_accuracy: 0.7375\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 10.8148 - accuracy: 0.7514 - val_loss: 11.6355 - val_accuracy: 0.7410\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 10.5050 - accuracy: 0.7548 - val_loss: 11.3534 - val_accuracy: 0.7437\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 10.2400 - accuracy: 0.7569 - val_loss: 11.1073 - val_accuracy: 0.7479\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 9.9747 - accuracy: 0.7601 - val_loss: 10.9980 - val_accuracy: 0.7430\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 9.7398 - accuracy: 0.7616 - val_loss: 10.6530 - val_accuracy: 0.7522\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 9.5179 - accuracy: 0.7645 - val_loss: 10.4929 - val_accuracy: 0.7516\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 9.3007 - accuracy: 0.7662 - val_loss: 10.2954 - val_accuracy: 0.7567\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 9.1157 - accuracy: 0.7677 - val_loss: 10.1181 - val_accuracy: 0.7567\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 8.9215 - accuracy: 0.7699 - val_loss: 10.0061 - val_accuracy: 0.7589\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 8.7521 - accuracy: 0.7718 - val_loss: 9.8081 - val_accuracy: 0.7573\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 8.5886 - accuracy: 0.7731 - val_loss: 9.6688 - val_accuracy: 0.7622\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 8.4283 - accuracy: 0.7737 - val_loss: 9.4811 - val_accuracy: 0.7640\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 8.2883 - accuracy: 0.7757 - val_loss: 9.4102 - val_accuracy: 0.7633\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 8.1405 - accuracy: 0.7765 - val_loss: 9.2294 - val_accuracy: 0.7643\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 8.0052 - accuracy: 0.7781 - val_loss: 9.1366 - val_accuracy: 0.7634\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 7.8777 - accuracy: 0.7790 - val_loss: 9.0333 - val_accuracy: 0.7659\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 7.7510 - accuracy: 0.7811 - val_loss: 8.8693 - val_accuracy: 0.7674\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 7.6206 - accuracy: 0.7817 - val_loss: 8.8201 - val_accuracy: 0.7666\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 7.5164 - accuracy: 0.7829 - val_loss: 8.6516 - val_accuracy: 0.7683\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 7.4038 - accuracy: 0.7829 - val_loss: 8.5484 - val_accuracy: 0.7717\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 7.2912 - accuracy: 0.7845 - val_loss: 8.4559 - val_accuracy: 0.7724\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 7.1928 - accuracy: 0.7861 - val_loss: 8.3460 - val_accuracy: 0.7725\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 7.0934 - accuracy: 0.7857 - val_loss: 8.2692 - val_accuracy: 0.7727\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.9855 - accuracy: 0.7872 - val_loss: 8.1738 - val_accuracy: 0.7742\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.8968 - accuracy: 0.7879 - val_loss: 8.0955 - val_accuracy: 0.7731\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.8066 - accuracy: 0.7890 - val_loss: 8.0333 - val_accuracy: 0.7765\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.7171 - accuracy: 0.7894 - val_loss: 7.9041 - val_accuracy: 0.7761\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.6339 - accuracy: 0.7910 - val_loss: 7.8631 - val_accuracy: 0.7731\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.5496 - accuracy: 0.7913 - val_loss: 7.8171 - val_accuracy: 0.7731\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.4683 - accuracy: 0.7918 - val_loss: 7.6807 - val_accuracy: 0.7761\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.3834 - accuracy: 0.7915 - val_loss: 7.6485 - val_accuracy: 0.7725\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.3113 - accuracy: 0.7931 - val_loss: 7.5633 - val_accuracy: 0.7813\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.2361 - accuracy: 0.7935 - val_loss: 7.4402 - val_accuracy: 0.7796\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.1562 - accuracy: 0.7938 - val_loss: 7.4422 - val_accuracy: 0.7782\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.0909 - accuracy: 0.7946 - val_loss: 7.3306 - val_accuracy: 0.7794\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.0195 - accuracy: 0.7949 - val_loss: 7.2704 - val_accuracy: 0.7803\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.9564 - accuracy: 0.7954 - val_loss: 7.1924 - val_accuracy: 0.7791\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.8827 - accuracy: 0.7959 - val_loss: 7.1413 - val_accuracy: 0.7800\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.8244 - accuracy: 0.7965 - val_loss: 7.0477 - val_accuracy: 0.7799\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.7570 - accuracy: 0.7963 - val_loss: 7.0317 - val_accuracy: 0.7776\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.6932 - accuracy: 0.7968 - val_loss: 6.9625 - val_accuracy: 0.7811\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.6359 - accuracy: 0.7985 - val_loss: 6.9304 - val_accuracy: 0.7808\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.5730 - accuracy: 0.7985 - val_loss: 6.8462 - val_accuracy: 0.7811\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.5189 - accuracy: 0.7986 - val_loss: 6.8065 - val_accuracy: 0.7825\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.4588 - accuracy: 0.7987 - val_loss: 6.7702 - val_accuracy: 0.7792\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.4084 - accuracy: 0.7992 - val_loss: 6.6996 - val_accuracy: 0.7804\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.3533 - accuracy: 0.7998 - val_loss: 6.6114 - val_accuracy: 0.7813\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.2989 - accuracy: 0.7997 - val_loss: 6.5623 - val_accuracy: 0.7822\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.2505 - accuracy: 0.8008 - val_loss: 6.5330 - val_accuracy: 0.7854\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.1924 - accuracy: 0.8016 - val_loss: 6.4583 - val_accuracy: 0.7825\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.1472 - accuracy: 0.8015 - val_loss: 6.4813 - val_accuracy: 0.7807\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.0991 - accuracy: 0.8012 - val_loss: 6.3873 - val_accuracy: 0.7810\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.0460 - accuracy: 0.8021 - val_loss: 6.3315 - val_accuracy: 0.7833\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.9990 - accuracy: 0.8019 - val_loss: 6.3150 - val_accuracy: 0.7803\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.9601 - accuracy: 0.8019 - val_loss: 6.2408 - val_accuracy: 0.7822\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.9044 - accuracy: 0.8040 - val_loss: 6.1792 - val_accuracy: 0.7843\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.8583 - accuracy: 0.8029 - val_loss: 6.2082 - val_accuracy: 0.7801\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.8228 - accuracy: 0.8033 - val_loss: 6.1338 - val_accuracy: 0.7818\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.7748 - accuracy: 0.8040 - val_loss: 6.0472 - val_accuracy: 0.7864\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.7319 - accuracy: 0.8043 - val_loss: 6.0419 - val_accuracy: 0.7836\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.6924 - accuracy: 0.8041 - val_loss: 6.0312 - val_accuracy: 0.7819\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.6461 - accuracy: 0.8042 - val_loss: 5.9587 - val_accuracy: 0.7826\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.6087 - accuracy: 0.8049 - val_loss: 5.8965 - val_accuracy: 0.7871\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.5685 - accuracy: 0.8054 - val_loss: 5.8590 - val_accuracy: 0.7837\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.5294 - accuracy: 0.8056 - val_loss: 5.8554 - val_accuracy: 0.7811\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.4846 - accuracy: 0.8061 - val_loss: 5.7754 - val_accuracy: 0.7854\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.4533 - accuracy: 0.8065 - val_loss: 5.7602 - val_accuracy: 0.7821\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.4124 - accuracy: 0.8063 - val_loss: 5.7172 - val_accuracy: 0.7867\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.3763 - accuracy: 0.8065 - val_loss: 5.6553 - val_accuracy: 0.7858\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.3402 - accuracy: 0.8058 - val_loss: 5.6303 - val_accuracy: 0.7846\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.3020 - accuracy: 0.8065 - val_loss: 5.6374 - val_accuracy: 0.7862\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.2650 - accuracy: 0.8071 - val_loss: 5.6266 - val_accuracy: 0.7839\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.2364 - accuracy: 0.8075 - val_loss: 5.5295 - val_accuracy: 0.7859\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.1999 - accuracy: 0.8078 - val_loss: 5.5256 - val_accuracy: 0.7866\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.1614 - accuracy: 0.8077 - val_loss: 5.4528 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.1334 - accuracy: 0.8076 - val_loss: 5.4400 - val_accuracy: 0.7849\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.0998 - accuracy: 0.8073 - val_loss: 5.3922 - val_accuracy: 0.7862\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.0696 - accuracy: 0.8081 - val_loss: 5.3638 - val_accuracy: 0.7862\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.0370 - accuracy: 0.8088 - val_loss: 5.3690 - val_accuracy: 0.7864\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.9992 - accuracy: 0.8093 - val_loss: 5.2870 - val_accuracy: 0.7865\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.9709 - accuracy: 0.8094 - val_loss: 5.2499 - val_accuracy: 0.7859\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.9438 - accuracy: 0.8087 - val_loss: 5.2322 - val_accuracy: 0.7853\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.9113 - accuracy: 0.8091 - val_loss: 5.2344 - val_accuracy: 0.7878\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.8815 - accuracy: 0.8091 - val_loss: 5.1719 - val_accuracy: 0.7868\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.8509 - accuracy: 0.8097 - val_loss: 5.1505 - val_accuracy: 0.7843\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.8215 - accuracy: 0.8097 - val_loss: 5.1708 - val_accuracy: 0.7843\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.7895 - accuracy: 0.8112 - val_loss: 5.0729 - val_accuracy: 0.7866\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 3.7660 - accuracy: 0.8101 - val_loss: 5.0775 - val_accuracy: 0.7878\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "fit_feedback = model.fit(x_train, y_train, \n",
    "                         validation_data=(x_test, y_test),\n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         epochs=EPOCHS,\n",
    "                         use_multiprocessing=True)\n",
    "model.save(os.path.join(MODEL_PATH, f'{model.name}.model'), save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b37907",
   "metadata": {},
   "source": [
    "Question 3 : A first linear neural network: performance \n",
    "---\n",
    "\n",
    "How many trainable parameters are contained in the whole network you just built? What are the measured train and test accuracies of the model you fitted in question 2?\n",
    "\n",
    "Report your answer under the format: *number_param*, *train_acc*, *test_acc* (use a decimal notation for the accuracies, not %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1bfa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_param, train_acc, test_acc :: 7850, 0.810, 0.788\n"
     ]
    }
   ],
   "source": [
    "# We already had the number of parameters in the model summary\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "history = fit_feedback.history\n",
    "number_param = tf.reduce_sum([reduce(operator.mul, v.shape) for v in model.trainable_variables]).numpy()\n",
    "train_acc = history[\"accuracy\"][-1]\n",
    "test_acc = history[\"val_accuracy\"][-1]\n",
    "\n",
    "print(f\"number_param, train_acc, test_acc :: {number_param}, {train_acc:.3f}, {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51987d97",
   "metadata": {},
   "source": [
    "Question 4 : A non-linear network \n",
    "---\n",
    "\n",
    "Build a new model, by adding a layer before the output layer of your neural net from question 1. This layer must be a dense layer with a tanh activation function, and should contain $100$ units. The kernel and bias are initialized to *random_normal*.\n",
    "\n",
    "Use a learning rate of $10^{-5}$.\n",
    "\n",
    "Implement you neural network in the variable *model*. Just define and compile the network, don't fit it on the training data (your submission will likely time out if you do!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82f4a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"non_linear\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\", activation=\"tanh\"),\n",
    "    tf.keras.layers.Dense(10, kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\", activation=\"softmax\"),\n",
    "], name=\"non_linear\")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb12b30",
   "metadata": {},
   "source": [
    "Question 5 : \n",
    "---\n",
    "\n",
    "Fit your model from question 4 on the train data with a batch size of $32$. Run $100$ epochs to fit your model.\n",
    "\n",
    "Once your neural network is fitted, save it in a *.model* file using the [save](https://www.tensorflow.org/guide/keras/save_and_serialize) function of Keras with *save_format='h5'* and upload it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13070d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3993 - accuracy: 0.2143 - val_loss: 1.5062 - val_accuracy: 0.4836\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3719 - accuracy: 0.5345 - val_loss: 1.1734 - val_accuracy: 0.5882\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0943 - accuracy: 0.6238 - val_loss: 1.0103 - val_accuracy: 0.6491\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9604 - accuracy: 0.6705 - val_loss: 0.9101 - val_accuracy: 0.6842\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8631 - accuracy: 0.7033 - val_loss: 0.8374 - val_accuracy: 0.7107\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7962 - accuracy: 0.7242 - val_loss: 0.7906 - val_accuracy: 0.7251\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7489 - accuracy: 0.7423 - val_loss: 0.7495 - val_accuracy: 0.7397\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7089 - accuracy: 0.7534 - val_loss: 0.7221 - val_accuracy: 0.7473\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6800 - accuracy: 0.7640 - val_loss: 0.6956 - val_accuracy: 0.7556\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6651 - accuracy: 0.7707 - val_loss: 0.6766 - val_accuracy: 0.7646\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6329 - accuracy: 0.7790 - val_loss: 0.6601 - val_accuracy: 0.7671\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6216 - accuracy: 0.7818 - val_loss: 0.6481 - val_accuracy: 0.7718\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6030 - accuracy: 0.7913 - val_loss: 0.6305 - val_accuracy: 0.7789\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5952 - accuracy: 0.7905 - val_loss: 0.6194 - val_accuracy: 0.7828\n",
      "Epoch 15/100\n",
      "1857/1875 [============================>.] - ETA: 0s - loss: 0.5837 - accuracy: 0.7955"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4510c1e84ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                          use_multiprocessing=True)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{model.name}.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ingi2262/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ingi2262/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ingi2262/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ingi2262/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/ingi2262/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ingi2262/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     \"\"\"\n\u001b[1;32m   1863\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mexecuting_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Copy saveable status of function's graph to current FuncGraph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "fit_feedback = model.fit(x_train, y_train, \n",
    "                         validation_data=(x_test, y_test),\n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         epochs=EPOCHS,\n",
    "                         use_multiprocessing=True)\n",
    "model.save(os.path.join(MODEL_PATH, f'{model.name}.model'), save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b7a8b",
   "metadata": {},
   "source": [
    "Question 6 : \n",
    "---\n",
    "\n",
    "How many trainable parameters are contained in the whole network you built in question 4? What are the measured train and test accuracies of the model as fitted in question 5?\n",
    "\n",
    "Report your answer under the format: *number_param*, *train_acc*, *test_acc* (use a decimal notation for the accuracies, not %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77629d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already had the number of parameters in the model summary\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "history = fit_feedback.history\n",
    "number_param = tf.reduce_sum([reduce(operator.mul, v.shape) for v in model.trainable_variables]).numpy()\n",
    "train_acc = history[\"accuracy\"][-1]\n",
    "test_acc = tanh_acc = history[\"val_accuracy\"][-1]\n",
    "\n",
    "print(f\"number_param, train_acc, test_acc :: {number_param}, {train_acc:.3f}, {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6068cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from time import time\n",
    "from tqdm import trange\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "N_RUNS = 10\n",
    "\n",
    "def get_accuracies(activation, output):\n",
    "    \n",
    "    def get_non_linear_model():\n",
    "        \"\"\"\n",
    "        Return the global model with the good activation function for the hidden layer\n",
    "        \"\"\"\n",
    "        \n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(100, kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\", activation=activation),\n",
    "            tf.keras.layers.Dense(10, kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\", activation=\"softmax\"),\n",
    "        ], name=\"non_linear\")\n",
    "        \n",
    "        model.compile(\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    mean_acc = .0\n",
    "    mean_elapsed = .0\n",
    "    global_start = time()\n",
    "    for run in range(N_RUNS):\n",
    "        start = time()\n",
    "        model = get_non_linear_model()\n",
    "        fit_feedback = model.fit(x_train, y_train, \n",
    "                                 validation_data=(x_test, y_test),\n",
    "                                 batch_size=BATCH_SIZE, \n",
    "                                 epochs=EPOCHS,\n",
    "                                 use_multiprocessing=True,\n",
    "                                 verbose=0)\n",
    "        acc =  fit_feedback.history[\"val_accuracy\"][-1]\n",
    "        output.append(acc)\n",
    "        \n",
    "        # Just needed to log\n",
    "        elapsed = time()-start\n",
    "        global_elapsed = time()-global_start\n",
    "        \n",
    "        mean_elapsed = ((run)*mean_elapsed + elapsed) / (run+1)\n",
    "        mean_acc = ((run)*mean_acc + acc) / (run+1)\n",
    "        \n",
    "        remaining_time = global_elapsed + (N_RUNS-(run+1)) * mean_elapsed\n",
    "        \n",
    "        print(f\"[{activation}] run {run+1}/{N_RUNS} :: mean accuracy={mean_acc:.3f} :: [{global_elapsed:.2f}s < {remaining_time:.2f}s]\")\n",
    "        \n",
    "\n",
    "# To run faster (while the cpu is not bottlenecked), we will run both model (tanh, relu) in parallel\n",
    "tanh_accuracies = list()\n",
    "relu_accuracies = list()\n",
    "tanh_thread = Thread(target=get_accuracies, kwargs=dict(activation=\"tanh\", output=tanh_accuracies))\n",
    "relu_thread = Thread(target=get_accuracies, kwargs=dict(activation=\"relu\", output=relu_accuracies))\n",
    "\n",
    "tanh_thread.start(); relu_thread.start();\n",
    "tanh_thread.join(); relu_thread.join();\n",
    "\n",
    "tanh_acc = tf.reduce_mean(tanh_accuracies).numpy()\n",
    "relu_acc = tf.reduce_mean(relu_accuracies).numpy()\n",
    "\n",
    "print(f'\\ntanh_acc, relu_acc :: {tanh_acc:.3f}, {relu_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba60254",
   "metadata": {},
   "source": [
    "Question 7 :\n",
    "---\n",
    "\n",
    "Besides a tanh activation funtion, other non-linear functions can be implemented in a hidden layer. Let's consider the ReLU activation: use the **exact** same network as in the previous question, but with ReLU instead of tanh activation in the hidden layer. Which one performs better?\n",
    "\n",
    "Since there is a lot of randomness involved, different training runs for the same network might yield different results. To get more robust results, perform $10$ distinct runs for each model and report the average test accuracies.\n",
    "\n",
    "Train each model during $100$ epochs.\n",
    "\n",
    "Report the mean test accuracy of both networks using the format: *tanh_acc*, *relu_acc* (use a decimal notation, not %)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c7e5b",
   "metadata": {},
   "source": [
    "Question 8 : Multiple choice\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea243147",
   "metadata": {},
   "source": [
    "- [ ] prout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9640d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ingi2261",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
