{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d49a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "from os.path import join  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.distribute import MirroredStrategy, OneDeviceStrategy\n",
    "\n",
    "from utils import *\n",
    "\n",
    "datasets = join(os.getcwd(), \"datasets\")\n",
    "preprocessed_datasets = join(datasets, \"preprocessed\")\n",
    "\n",
    "X_all_sep, y_all, X_test_sep = pickle.load(open(join(preprocessed_datasets, \"cleaned_separated.pickle\"), 'rb'))\n",
    "X_all_ohe, _, X_test_ohe = pickle.load(open(join(preprocessed_datasets, \"cleaned_ohe.pickle\"), 'rb'))\n",
    "\n",
    "ohe_split =  X_all_ohe.shape[1] - X_all_sep[0].shape[1]\n",
    "X_all = (*X_all_sep, X_all_ohe[:,-ohe_split:])\n",
    "X_test = (*X_test_sep, X_test_ohe[:,-ohe_split:])\n",
    "\n",
    "strategy = OneDeviceStrategy(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7482ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_tuple_split(X, y, train_size, seed=None):\n",
    "    def apply_tuple_split(X, split):\n",
    "        train, test = [], []\n",
    "        for x in X:\n",
    "            train.append(x[:split])\n",
    "            test.append(x[split:])\n",
    "        return tuple(train), tuple(test)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    indices_ = np.arange(len(y))\n",
    "    np.random.shuffle(indices_)\n",
    "    \n",
    "    splitter_indice = int(len(y) * train_size)\n",
    "    train_indices, test_indices = np.split(indices_, [splitter_indice])\n",
    "    \n",
    "    X_train, X_test = apply_tuple_split(X, splitter_indice)\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_tuple_split(X_all, y_all, .75, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cea42c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 6, 128)       4480        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6, 1)         129         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1306624)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 132)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1306762)      0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1306763     concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,311,372\n",
      "Trainable params: 1,311,372\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    conv_len, vp_len, ohe_len = len(X_train[0][-1]), len(X_train[1][-1]), len(X_train[2][-1])\n",
    "    # vocab_dim = int(1.2*len(np.unique(np.r_[X_train[1], X_test[1]])))\n",
    "    vocab_dim = int(np.unique(np.r_[X_train[1], X_test[1]]).max())+1\n",
    "    \n",
    "    conv_input = tf.keras.layers.Input(shape=(conv_len,))\n",
    "    \n",
    "    \n",
    "    vp_input = tf.keras.layers.Input(shape=(vp_len,))\n",
    "    embedded = tf.keras.layers.Embedding(vocab_dim, 128, input_length=vp_len)(vp_input)\n",
    "    dense_emb = tf.keras.layers.Dense(1)(embedded)\n",
    "    flatten_emb = tf.keras.layers.Flatten()(dense_emb)\n",
    "    \n",
    "    ohe_input = tf.keras.layers.Input(shape=(ohe_len,))\n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate()([conv_input, flatten_emb, ohe_input])\n",
    "    \n",
    "    output = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.L1(0.01), activation='sigmoid')(concat)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[conv_input, vp_input, ohe_input], outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "        metrics=[bcr, p1, p2, m1, m2, \"accuracy\"]\n",
    "    )\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_bcr', factor=.5, patience=10, verbose=2),\n",
    "    BCREarlyStopping(patience=30, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84c00e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - ETA: 2s - loss: 24.5676 - bcr: 0.5059 - p1: 1.0000 - p2: 0.0118 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.300 - ETA: 0s - loss: 605.7090 - bcr: 0.5044 - p1: 0.7500 - p2: 0.2588 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.38 - 4s 2s/step - loss: 799.4228 - bcr: 0.5039 - p1: 0.6667 - p2: 0.3412 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.4088 - val_loss: 4484.6787 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romaingrx/Nextcloud/EPL/Q8/Cours/LINGI2262 - Machine Learning/LINGI2262-Projects/Assignment 5 - A Machine Learning Competition/utils.py:105: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return bcr - bcr_delta * (1 - np.exp(-bcr_delta / sigma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best p value : 0.5\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 3051.6477 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 43.0000 - m2: 77.0000 - accuracy: 0.641 - ETA: 0s - loss: 2868.6289 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 40.2500 - m2: 77.5000 - accuracy: 0.658 - 1s 428ms/step - loss: 2807.6226 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 39.3333 - m2: 77.6667 - accuracy: 0.6641 - val_loss: 3273.9280 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romaingrx/Nextcloud/EPL/Q8/Cours/LINGI2262 - Machine Learning/LINGI2262-Projects/Assignment 5 - A Machine Learning Competition/utils.py:105: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return bcr - bcr_delta * (1 - np.exp(-bcr_delta / sigma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1714.6387 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.725 - ETA: 0s - loss: 1641.3342 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.700 - 1s 430ms/step - loss: 1616.8994 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.6919 - val_loss: 253.2992 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 141.4025 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.69 - ETA: 0s - loss: 618.0826 - bcr: 0.5000 - p1: 0.2500 - p2: 0.7500 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.6077   - 1s 438ms/step - loss: 776.9760 - bcr: 0.5000 - p1: 0.3333 - p2: 0.6667 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.5798 - val_loss: 2037.4734 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 2736.3679 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 43.0000 - m2: 77.0000 - accuracy: 0.358 - ETA: 0s - loss: 2693.1907 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 40.2500 - m2: 77.5000 - accuracy: 0.341 - 1s 439ms/step - loss: 2678.7983 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 39.3333 - m2: 77.6667 - accuracy: 0.3359 - val_loss: 736.5608 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1112.1243 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 32.0000 - m2: 88.0000 - accuracy: 0.266 - ETA: 0s - loss: 977.3889 - bcr: 0.5000 - p1: 0.7500 - p2: 0.2500 - m1: 34.7500 - m2: 83.0000 - accuracy: 0.3498    - 1s 443ms/step - loss: 932.4771 - bcr: 0.5000 - p1: 0.6667 - p2: 0.3333 - m1: 35.6667 - m2: 81.3333 - accuracy: 0.3775 - val_loss: 1832.4625 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1034.6783 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.691 - ETA: 0s - loss: 1169.3404 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.683 - 1s 443ms/step - loss: 1214.2277 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.6808 - val_loss: 2696.0271 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1602.3052 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.683 - ETA: 0s - loss: 1603.7995 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.679 - 1s 443ms/step - loss: 1604.2976 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.6780 - val_loss: 2224.4004 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 1367.6360 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.666 - ETA: 0s - loss: 1258.2707 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.671 - 1s 449ms/step - loss: 1221.8156 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.6724 - val_loss: 707.4591 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 428.2867 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 43.0000 - m2: 77.0000 - accuracy: 0.64 - ETA: 0s - loss: 441.2318 - bcr: 0.5000 - p1: 0.2500 - p2: 0.7500 - m1: 40.2500 - m2: 77.5000 - accuracy: 0.5568   - 1s 445ms/step - loss: 445.5468 - bcr: 0.5000 - p1: 0.3333 - p2: 0.6667 - m1: 39.3333 - m2: 77.6667 - accuracy: 0.5285 - val_loss: 668.0683 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5256\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 800.0803 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 46.0000 - m2: 74.0000 - accuracy: 0.38 - ETA: 0s - loss: 756.7364 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 41.7500 - m2: 76.0000 - accuracy: 0.35 - 1s 445ms/step - loss: 742.2885 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 40.3333 - m2: 76.6667 - accuracy: 0.3442 - val_loss: 322.5666 - val_bcr: 0.5096 - val_p1: 0.0732 - val_p2: 0.9459 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 136.6969 - bcr: 0.5739 - p1: 0.1714 - p2: 0.9765 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.74 - ETA: 0s - loss: 185.5669 - bcr: 0.5586 - p1: 0.1348 - p2: 0.9824 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.71 - 1s 443ms/step - loss: 201.8569 - bcr: 0.5535 - p1: 0.1226 - p2: 0.9843 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.7119 - val_loss: 675.4095 - val_bcr: 0.5122 - val_p1: 0.0244 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "New best p value : 0.5145556734294201\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 346.1117 - bcr: 0.5263 - p1: 0.0526 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.70 - ETA: 0s - loss: 349.5822 - bcr: 0.5197 - p1: 0.0395 - p2: 1.0000 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.69 - 1s 451ms/step - loss: 350.7391 - bcr: 0.5175 - p1: 0.0351 - p2: 1.0000 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.6893 - val_loss: 486.1283 - val_bcr: 0.4987 - val_p1: 0.0244 - val_p2: 0.9730 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 225.3288 - bcr: 0.5143 - p1: 0.0286 - p2: 1.0000 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.71 - ETA: 0s - loss: 198.0578 - bcr: 0.5384 - p1: 0.0839 - p2: 0.9930 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.71 - 1s 441ms/step - loss: 188.9675 - bcr: 0.5465 - p1: 0.1024 - p2: 0.9906 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.7151 - val_loss: 140.0686 - val_bcr: 0.5689 - val_p1: 0.9756 - val_p2: 0.1622 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5897\n",
      "New best p value : 0.5614986011618932\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 90.9063 - bcr: 0.6892 - p1: 1.0000 - p2: 0.3784 - m1: 46.0000 - m2: 74.0000 - accuracy: 0.616 - ETA: 0s - loss: 148.6476 - bcr: 0.6434 - p1: 1.0000 - p2: 0.2868 - m1: 41.7500 - m2: 76.0000 - accuracy: 0.53 - 1s 439ms/step - loss: 167.8947 - bcr: 0.6282 - p1: 1.0000 - p2: 0.2563 - m1: 40.3333 - m2: 76.6667 - accuracy: 0.5057 - val_loss: 135.6050 - val_bcr: 0.5689 - val_p1: 0.9756 - val_p2: 0.1622 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5897\n",
      "New best p value : 0.5807903942661091\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 102.0304 - bcr: 0.6835 - p1: 1.0000 - p2: 0.3671 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.58 - ETA: 0s - loss: 97.3631 - bcr: 0.6643 - p1: 0.8162 - p2: 0.5123 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.6207 - 1s 439ms/step - loss: 95.8074 - bcr: 0.6578 - p1: 0.7549 - p2: 0.5607 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.6331 - val_loss: 396.5935 - val_bcr: 0.4987 - val_p1: 0.0244 - val_p2: 0.9730 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 191.5146 - bcr: 0.5250 - p1: 0.0500 - p2: 1.0000 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.68 - ETA: 0s - loss: 195.4385 - bcr: 0.5223 - p1: 0.0446 - p2: 1.0000 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.68 - 1s 448ms/step - loss: 196.7465 - bcr: 0.5214 - p1: 0.0429 - p2: 1.0000 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.6867 - val_loss: 377.2330 - val_bcr: 0.5122 - val_p1: 0.0244 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 177.4795 - bcr: 0.5122 - p1: 0.0244 - p2: 1.0000 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.66 - ETA: 0s - loss: 150.8767 - bcr: 0.5410 - p1: 0.0918 - p2: 0.9903 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.68 - 1s 450ms/step - loss: 142.0091 - bcr: 0.5507 - p1: 0.1143 - p2: 0.9870 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.6955 - val_loss: 109.6397 - val_bcr: 0.5837 - val_p1: 0.9512 - val_p2: 0.2162 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.6026\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 76.3415 - bcr: 0.7099 - p1: 1.0000 - p2: 0.4198 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.608 - ETA: 0s - loss: 93.6233 - bcr: 0.6724 - p1: 1.0000 - p2: 0.3448 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.559 - 1s 443ms/step - loss: 99.3840 - bcr: 0.6599 - p1: 1.0000 - p2: 0.3198 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.5433 - val_loss: 75.0641 - val_bcr: 0.4654 - val_p1: 0.3902 - val_p2: 0.5405 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 33.0688 - bcr: 0.8193 - p1: 0.8947 - p2: 0.7439 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.791 - ETA: 0s - loss: 46.9934 - bcr: 0.7699 - p1: 0.7319 - p2: 0.8079 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.781 - 1s 457ms/step - loss: 51.6349 - bcr: 0.7534 - p1: 0.6776 - p2: 0.8293 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.7776 - val_loss: 322.6851 - val_bcr: 0.5122 - val_p1: 0.0244 - val_p2: 1.0000 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 126.0798 - bcr: 0.5152 - p1: 0.0303 - p2: 1.0000 - m1: 33.0000 - m2: 87.0000 - accuracy: 0.73 - ETA: 0s - loss: 125.8382 - bcr: 0.5233 - p1: 0.0465 - p2: 1.0000 - m1: 35.2500 - m2: 82.5000 - accuracy: 0.71 - 1s 456ms/step - loss: 125.7577 - bcr: 0.5260 - p1: 0.0519 - p2: 1.0000 - m1: 36.0000 - m2: 81.0000 - accuracy: 0.7091 - val_loss: 143.2827 - val_bcr: 0.4690 - val_p1: 0.0732 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4487\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 34.9545 - bcr: 0.7635 - p1: 0.5641 - p2: 0.9630 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.833 - ETA: 0s - loss: 39.3982 - bcr: 0.7643 - p1: 0.6731 - p2: 0.8556 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.797 - 1s 451ms/step - loss: 40.8795 - bcr: 0.7646 - p1: 0.7094 - p2: 0.8198 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.7857 - val_loss: 127.6132 - val_bcr: 0.5162 - val_p1: 0.9512 - val_p2: 0.0811 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 96.8406 - bcr: 0.6582 - p1: 1.0000 - p2: 0.3165 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.550 - ETA: 0s - loss: 81.3769 - bcr: 0.6932 - p1: 0.9412 - p2: 0.4451 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.612 - 1s 437ms/step - loss: 76.2224 - bcr: 0.7048 - p1: 0.9216 - p2: 0.4880 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.6335 - val_loss: 185.8252 - val_bcr: 0.4974 - val_p1: 0.0488 - val_p2: 0.9459 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 47.5596 - bcr: 0.6562 - p1: 0.3125 - p2: 1.0000 - m1: 32.0000 - m2: 88.0000 - accuracy: 0.816 - ETA: 0s - loss: 60.7239 - bcr: 0.6404 - p1: 0.2809 - p2: 1.0000 - m1: 34.7500 - m2: 83.0000 - accuracy: 0.785 - 1s 446ms/step - loss: 65.1121 - bcr: 0.6352 - p1: 0.2703 - p2: 1.0000 - m1: 35.6667 - m2: 81.3333 - accuracy: 0.7744 - val_loss: 166.5696 - val_bcr: 0.4703 - val_p1: 0.0488 - val_p2: 0.8919 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4487\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 42.9957 - bcr: 0.6800 - p1: 0.3846 - p2: 0.9753 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.783 - ETA: 0s - loss: 39.2137 - bcr: 0.7196 - p1: 0.5176 - p2: 0.9215 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.789 - 1s 448ms/step - loss: 37.9531 - bcr: 0.7328 - p1: 0.5620 - p2: 0.9035 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.7921 - val_loss: 96.1554 - val_bcr: 0.5606 - val_p1: 0.8780 - val_p2: 0.2432 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5769\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 64.2212 - bcr: 0.7654 - p1: 1.0000 - p2: 0.5309 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.683 - ETA: 0s - loss: 56.1910 - bcr: 0.7924 - p1: 1.0000 - p2: 0.5848 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.718 - 1s 463ms/step - loss: 53.5143 - bcr: 0.8014 - p1: 1.0000 - p2: 0.6028 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.7299 - val_loss: 141.4196 - val_bcr: 0.4812 - val_p1: 0.0976 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 34.9273 - bcr: 0.7370 - p1: 0.4857 - p2: 0.9882 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.841 - ETA: 0s - loss: 41.3784 - bcr: 0.7041 - p1: 0.4205 - p2: 0.9877 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.810 - 1s 456ms/step - loss: 43.5288 - bcr: 0.6931 - p1: 0.3988 - p2: 0.9875 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.8000 - val_loss: 136.1255 - val_bcr: 0.4812 - val_p1: 0.0976 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 39.6063 - bcr: 0.7491 - p1: 0.5238 - p2: 0.9744 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.816 - ETA: 0s - loss: 36.2569 - bcr: 0.7862 - p1: 0.6429 - p2: 0.9295 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.826 - 1s 450ms/step - loss: 35.1404 - bcr: 0.7985 - p1: 0.6825 - p2: 0.9145 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.8292 - val_loss: 86.9929 - val_bcr: 0.5498 - val_p1: 0.8293 - val_p2: 0.2703 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5641\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 55.1383 - bcr: 0.7765 - p1: 1.0000 - p2: 0.5529 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.683 - ETA: 0s - loss: 46.7315 - bcr: 0.7999 - p1: 0.9563 - p2: 0.6436 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.731 - 1s 449ms/step - loss: 43.9292 - bcr: 0.8077 - p1: 0.9417 - p2: 0.6738 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.7473 - val_loss: 136.7273 - val_bcr: 0.4812 - val_p1: 0.0976 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 33.2356 - bcr: 0.7597 - p1: 0.5429 - p2: 0.9765 - m1: 35.0000 - m2: 85.0000 - accuracy: 0.850 - ETA: 0s - loss: 33.4393 - bcr: 0.7510 - p1: 0.5196 - p2: 0.9824 - m1: 36.2500 - m2: 81.5000 - accuracy: 0.838 - 1s 448ms/step - loss: 33.5072 - bcr: 0.7481 - p1: 0.5119 - p2: 0.9843 - m1: 36.6667 - m2: 80.3333 - accuracy: 0.8346 - val_loss: 115.7431 - val_bcr: 0.4677 - val_p1: 0.0976 - val_p2: 0.8378 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4487\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 29.6181 - bcr: 0.7439 - p1: 0.5000 - p2: 0.9878 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.833 - ETA: 0s - loss: 26.6918 - bcr: 0.7910 - p1: 0.6115 - p2: 0.9706 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.856 - 1s 445ms/step - loss: 25.7163 - bcr: 0.8067 - p1: 0.6486 - p2: 0.9648 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.8636 - val_loss: 71.5299 - val_bcr: 0.5036 - val_p1: 0.6829 - val_p2: 0.3243 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 31.1753 - bcr: 0.8554 - p1: 1.0000 - p2: 0.7108 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.800 - ETA: 0s - loss: 31.5038 - bcr: 0.8453 - p1: 1.0000 - p2: 0.6907 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.789 - 1s 442ms/step - loss: 31.6133 - bcr: 0.8420 - p1: 1.0000 - p2: 0.6839 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.7861 - val_loss: 71.1070 - val_bcr: 0.4829 - val_p1: 0.3171 - val_p2: 0.6486 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 18.2623 - bcr: 0.9080 - p1: 0.9070 - p2: 0.9091 - m1: 43.0000 - m2: 77.0000 - accuracy: 0.908 - ETA: 0s - loss: 18.7904 - bcr: 0.8849 - p1: 0.8443 - p2: 0.9255 - m1: 40.2500 - m2: 77.5000 - accuracy: 0.902 - 1s 456ms/step - loss: 18.9665 - bcr: 0.8772 - p1: 0.8234 - p2: 0.9310 - m1: 39.3333 - m2: 77.6667 - accuracy: 0.9002 - val_loss: 128.5657 - val_bcr: 0.4812 - val_p1: 0.0976 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 25.6593 - bcr: 0.7632 - p1: 0.5263 - p2: 1.0000 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.850 - ETA: 0s - loss: 25.8964 - bcr: 0.7616 - p1: 0.5299 - p2: 0.9932 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.844 - 1s 465ms/step - loss: 25.9755 - bcr: 0.7610 - p1: 0.5311 - p2: 0.9910 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.8432 - val_loss: 89.6037 - val_bcr: 0.4908 - val_p1: 0.1707 - val_p2: 0.8108 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.0318 - bcr: 0.8974 - p1: 0.8333 - p2: 0.9615 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.916 - ETA: 0s - loss: 16.7799 - bcr: 0.8919 - p1: 0.8447 - p2: 0.9391 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.906 - 1s 467ms/step - loss: 17.0293 - bcr: 0.8901 - p1: 0.8485 - p2: 0.9316 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9030 - val_loss: 65.5509 - val_bcr: 0.5333 - val_p1: 0.6341 - val_p2: 0.4324 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5385\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 27.4764 - bcr: 0.8693 - p1: 1.0000 - p2: 0.7386 - m1: 32.0000 - m2: 88.0000 - accuracy: 0.808 - ETA: 0s - loss: 24.5276 - bcr: 0.8796 - p1: 0.9884 - p2: 0.7709 - m1: 34.7500 - m2: 83.0000 - accuracy: 0.830 - 1s 448ms/step - loss: 23.5447 - bcr: 0.8831 - p1: 0.9845 - p2: 0.7816 - m1: 35.6667 - m2: 81.3333 - accuracy: 0.8380 - val_loss: 78.2029 - val_bcr: 0.4624 - val_p1: 0.1951 - val_p2: 0.7297 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4487\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.6620 - bcr: 0.8875 - p1: 0.8500 - p2: 0.9250 - m1: 40.0000 - m2: 80.0000 - accuracy: 0.900 - ETA: 0s - loss: 16.5173 - bcr: 0.8854 - p1: 0.8304 - p2: 0.9405 - m1: 38.7500 - m2: 79.0000 - accuracy: 0.904 - 1s 446ms/step - loss: 16.4691 - bcr: 0.8847 - p1: 0.8238 - p2: 0.9456 - m1: 38.3333 - m2: 78.6667 - accuracy: 0.9061 - val_loss: 107.9675 - val_bcr: 0.4812 - val_p1: 0.0976 - val_p2: 0.8649 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 18.9408 - bcr: 0.8378 - p1: 0.6757 - p2: 1.0000 - m1: 37.0000 - m2: 83.0000 - accuracy: 0.900 - ETA: 0s - loss: 18.7354 - bcr: 0.8388 - p1: 0.6844 - p2: 0.9932 - m1: 37.2500 - m2: 80.5000 - accuracy: 0.895 - 1s 457ms/step - loss: 18.6669 - bcr: 0.8391 - p1: 0.6873 - p2: 0.9909 - m1: 37.3333 - m2: 79.6667 - accuracy: 0.8945 - val_loss: 75.2408 - val_bcr: 0.4489 - val_p1: 0.1951 - val_p2: 0.7027 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4359\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.0821 - bcr: 0.9148 - p1: 0.8810 - p2: 0.9487 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.925 - ETA: 0s - loss: 15.1076 - bcr: 0.9227 - p1: 0.9031 - p2: 0.9423 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.927 - 1s 462ms/step - loss: 15.1161 - bcr: 0.9254 - p1: 0.9105 - p2: 0.9402 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9288 - val_loss: 61.5572 - val_bcr: 0.5089 - val_p1: 0.5854 - val_p2: 0.4324 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.5128\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 22.2354 - bcr: 0.8739 - p1: 0.9756 - p2: 0.7722 - m1: 41.0000 - m2: 79.0000 - accuracy: 0.841 - ETA: 0s - loss: 19.8573 - bcr: 0.8899 - p1: 0.9670 - p2: 0.8129 - m1: 39.2500 - m2: 78.5000 - accuracy: 0.864 - 1s 464ms/step - loss: 19.0646 - bcr: 0.8953 - p1: 0.9641 - p2: 0.8265 - m1: 38.6667 - m2: 78.3333 - accuracy: 0.8722 - val_loss: 74.1319 - val_bcr: 0.4489 - val_p1: 0.1951 - val_p2: 0.7027 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4359\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.9919 - bcr: 0.9174 - p1: 0.8718 - p2: 0.9630 - m1: 39.0000 - m2: 81.0000 - accuracy: 0.933 - ETA: 0s - loss: 13.7822 - bcr: 0.9069 - p1: 0.8483 - p2: 0.9656 - m1: 38.2500 - m2: 79.5000 - accuracy: 0.927 - 1s 460ms/step - loss: 13.7123 - bcr: 0.9034 - p1: 0.8405 - p2: 0.9664 - m1: 38.0000 - m2: 79.0000 - accuracy: 0.9258 - val_loss: 88.6470 - val_bcr: 0.4786 - val_p1: 0.1463 - val_p2: 0.8108 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 17.1780 - bcr: 0.8443 - p1: 0.7143 - p2: 0.9744 - m1: 42.0000 - m2: 78.0000 - accuracy: 0.883 - ETA: 0s - loss: 15.6735 - bcr: 0.8746 - p1: 0.7781 - p2: 0.9712 - m1: 39.7500 - m2: 78.0000 - accuracy: 0.902 - 1s 464ms/step - loss: 15.1720 - bcr: 0.8848 - p1: 0.7994 - p2: 0.9701 - m1: 39.0000 - m2: 78.0000 - accuracy: 0.9092 - val_loss: 68.1059 - val_bcr: 0.4977 - val_p1: 0.2927 - val_p2: 0.7027 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4872\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.2853 - bcr: 0.9384 - p1: 0.9118 - p2: 0.9651 - m1: 34.0000 - m2: 86.0000 - accuracy: 0.950 - ETA: 0s - loss: 12.3973 - bcr: 0.9370 - p1: 0.9216 - p2: 0.9524 - m1: 35.7500 - m2: 82.0000 - accuracy: 0.944 - 1s 475ms/step - loss: 12.4346 - bcr: 0.9365 - p1: 0.9249 - p2: 0.9482 - m1: 36.3333 - m2: 80.6667 - accuracy: 0.9429 - val_loss: 62.1459 - val_bcr: 0.4815 - val_p1: 0.3415 - val_p2: 0.6216 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4744\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 13.0968 - bcr: 0.9441 - p1: 0.9643 - p2: 0.9239 - m1: 28.0000 - m2: 92.0000 - accuracy: 0.933 - ETA: 0s - loss: 12.7474 - bcr: 0.9481 - p1: 0.9573 - p2: 0.9390 - m1: 32.7500 - m2: 85.0000 - accuracy: 0.940 - 1s 493ms/step - loss: 12.6309 - bcr: 0.9495 - p1: 0.9549 - p2: 0.9441 - m1: 34.3333 - m2: 82.6667 - accuracy: 0.9431 - val_loss: 70.2128 - val_bcr: 0.4624 - val_p1: 0.1951 - val_p2: 0.7297 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4487\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.8637 - bcr: 0.9230 - p1: 0.8947 - p2: 0.9512 - m1: 38.0000 - m2: 82.0000 - accuracy: 0.933 - ETA: 0s - loss: 11.7794 - bcr: 0.9321 - p1: 0.9008 - p2: 0.9634 - m1: 37.7500 - m2: 80.0000 - accuracy: 0.942 - 1s 465ms/step - loss: 11.7513 - bcr: 0.9351 - p1: 0.9028 - p2: 0.9675 - m1: 37.6667 - m2: 79.3333 - accuracy: 0.9460 - val_loss: 72.8845 - val_bcr: 0.4773 - val_p1: 0.1707 - val_p2: 0.7838 - val_m1: 41.0000 - val_m2: 37.0000 - val_accuracy: 0.4615\n",
      "Restoring model weights from the end of the best epoch. Best value : 0.581\n",
      "Epoch 00045: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    batch_size=120,\n",
    "                    epochs=200,\n",
    "                    callbacks=callbacks\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e403428f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Report for Functional -------------------\n",
      "\n",
      "P score : 0.573\n",
      "BCR     : 0.673\n",
      "BCR hat : 0.569\n"
     ]
    }
   ],
   "source": [
    "report = Report(model, X_train, y_train, X_val, y_val).to_stdout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ingi2262",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
