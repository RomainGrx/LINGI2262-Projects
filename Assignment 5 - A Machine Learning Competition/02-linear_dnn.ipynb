{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a5c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "from os.path import join  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "datasets = join(os.getcwd(), \"datasets\")\n",
    "preprocessed_datasets = join(datasets, \"preprocessed\")\n",
    "\n",
    "X_all, y_all, X_test = pickle.load(open(join(preprocessed_datasets, \"cleaned_ohe.pickle\"), 'rb'))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, shuffle=True, train_size=.75, random_state=42)\n",
    "\n",
    "strategy = MirroredStrategy([\"GPU:0\", \"GPU:1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2b7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCR(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='BCR', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "        self.TP = tf.keras.metrics.TruePositives()\n",
    "        self.TN = tf.keras.metrics.TrueNegatives()\n",
    "        self.FP = tf.keras.metrics.FalsePositives()\n",
    "        self.FN = tf.keras.metrics.FalseNegatives()\n",
    "        \n",
    "        self.bcr = self.add_weight(name='bcr', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        self.TP.update_state(y_true, y_pred)\n",
    "        self.TN.update_state(y_true, y_pred)\n",
    "        self.FP.update_state(y_true, y_pred)\n",
    "        self.FN.update_state(y_true, y_pred)\n",
    "        \n",
    "        tp = self.TP.result() \n",
    "        tn = self.TN.result()\n",
    "        fp = self.FP.result()\n",
    "        fn = self.FN.result()\n",
    "        \n",
    "        self.bcr.assign(.5 * ((tp / (tp + fn)) + (tn / (fp + tn))))\n",
    "    \n",
    "    def result(self):\n",
    "        return self.bcr\n",
    "        \n",
    "    def reset_states(self):\n",
    "        self.bcr.assign(0.0)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return tp / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "def bcr(y_true, y_pred):\n",
    "    return .5 * (recall(y_true, y_pred) + specificity(y_true, y_pred))\n",
    "\n",
    "def p1(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    m = m1(y_true, y_pred)\n",
    "    return tp / (m + K.epsilon())\n",
    "\n",
    "def p2(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    m = m2(y_true, y_pred)\n",
    "    return tn / (m + K.epsilon())\n",
    "\n",
    "def m1(y_true, y_pred):\n",
    "    return K.sum(K.round(y_true))\n",
    "\n",
    "def m2(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "\n",
    "def P(bcr, bcr_hat, p1, p2, m1, m2):\n",
    "    bcr_delta = np.abs(bcr - bcr_hat)\n",
    "    sigma = .5 * np.sqrt(((1-p1)*p1/m1) + (p2*(1-p2)/m2))\n",
    "    return bcr - bcr_delta * (1 - np.exp(- bcr_delta / sigma))\n",
    "\n",
    "def P_model(model, X_train, y_train, X_val, y_val, with_info=False):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    bcr_ = bcr(y_train, y_train_pred)\n",
    "    bcr_hat = bcr(y_val, y_val_pred)\n",
    "    \n",
    "    p1_ = p1(y_val, y_val_pred)\n",
    "    p2_ = p2(y_val, y_val_pred)\n",
    "    m1_ = m1(y_val, y_val_pred)\n",
    "    m2_ = m2(y_val, y_val_pred)\n",
    "    \n",
    "    p = P(bcr_, bcr_hat, p1_, p2_, m1_, m2_)\n",
    "    \n",
    "    if with_info:\n",
    "        return p, {'bcr':bcr_, 'bcr_hat':bcr_hat, 'p1':p1_, 'p2':p2_, 'm1':m1_, 'm2':m2_}\n",
    "    \n",
    "    return p\n",
    "    \n",
    "\n",
    "class BCREarlyStopping(keras.callbacks.Callback):\n",
    "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
    "\n",
    "      Arguments:\n",
    "          patience: Number of epochs to wait after min has been hit. After this\n",
    "          number of no improvement, training stops.\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self, patience=0, restore_best_weights=False):\n",
    "        super(BCREarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = .0\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        bcr = logs.get(\"bcr\")\n",
    "        val_bcr = logs.get(\"val_bcr\")\n",
    "        p1 = logs.get(\"val_p1\")\n",
    "        p2 = logs.get(\"val_p2\")\n",
    "        m1 = logs.get(\"val_m1\")\n",
    "        m2 = logs.get(\"val_m2\")\n",
    "        current = P(bcr, val_bcr, p1, p2, m1, m2)\n",
    "        \n",
    "        if np.less(self.best, current):\n",
    "            print(f\"New best p value : {current}\")\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (less).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                if self.restore_best_weights:\n",
    "                    print(f\"Restoring model weights from the end of the best epoch. Best value : {self.best:.3f}\")\n",
    "                    self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ea814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 1306757   \n",
      "=================================================================\n",
      "Total params: 1,306,757\n",
      "Trainable params: 1,306,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.L2(0.0), activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "        metrics=[bcr, p1, p2, m1, m2, \"accuracy\"]\n",
    "        # metrics=[bcr, \"accuracy\"]\n",
    "    )\n",
    "\n",
    "bcr_early_stop = BCREarlyStopping(patience=30, restore_best_weights=True)\n",
    "\n",
    "callbacks = [\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor='val_bcr', patience=20, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_bcr', factor=.5, patience=10, verbose=2),\n",
    "    bcr_early_stop\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09caa70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "4/4 [==============================] - 6s 454ms/step - loss: 1601.5394 - bcr: 0.5000 - p1: 0.5333 - p2: 0.4667 - m1: 12.4000 - m2: 18.3500 - accuracy: 0.5377 - val_loss: 956.1047 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7179\n",
      "Epoch 2/200\n",
      "2/4 [==============>...............] - ETA: 0s - loss: 1513.1500 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 12.0000 - m2: 20.0000 - accuracy: 0.6250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romaingrx/anaconda3/envs/ingi2262/lib/python3.7/site-packages/ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 128ms/step - loss: 1964.9074 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 11.9000 - m2: 18.8500 - accuracy: 0.6122 - val_loss: 1580.6410 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7179\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 1513.9815 - bcr: 0.5212 - p1: 0.1423 - p2: 0.9000 - m1: 12.0833 - m2: 18.6667 - accuracy: 0.6103 - val_loss: 2394.3289 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.2821\n",
      "New best p value : 0.4999999701976776\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 1688.3709 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 12.8167 - m2: 17.9333 - accuracy: 0.4164 - val_loss: 527.3217 - val_bcr: 0.4948 - val_p1: 0.0000e+00 - val_p2: 0.9896 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7051\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 1204.7530 - bcr: 0.5000 - p1: 0.0000e+00 - p2: 1.0000 - m1: 12.5833 - m2: 18.1667 - accuracy: 0.5909 - val_loss: 1159.9606 - val_bcr: 0.5000 - val_p1: 0.0000e+00 - val_p2: 1.0000 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7179\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 1221.2277 - bcr: 0.5308 - p1: 0.0879 - p2: 0.9737 - m1: 12.2333 - m2: 18.5167 - accuracy: 0.6216 - val_loss: 1142.7363 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.2821\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 1002.1667 - bcr: 0.5000 - p1: 1.0000 - p2: 0.0000e+00 - m1: 12.9167 - m2: 17.8333 - accuracy: 0.4195 - val_loss: 318.2181 - val_bcr: 0.6354 - val_p1: 0.3854 - val_p2: 0.8854 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7051\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 627.4690 - bcr: 0.5169 - p1: 0.1171 - p2: 0.9167 - m1: 12.2000 - m2: 18.5500 - accuracy: 0.5994 - val_loss: 589.5557 - val_bcr: 0.5104 - val_p1: 0.0312 - val_p2: 0.9896 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7179\n",
      "New best p value : 0.5156837665739191\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 530.6508 - bcr: 0.5519 - p1: 0.2576 - p2: 0.8462 - m1: 12.2000 - m2: 18.5500 - accuracy: 0.6327 - val_loss: 1055.4474 - val_bcr: 0.5000 - val_p1: 1.0000 - val_p2: 0.0000e+00 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.2821\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 527.0361 - bcr: 0.5384 - p1: 0.8273 - p2: 0.2496 - m1: 12.1500 - m2: 18.6000 - accuracy: 0.4640 - val_loss: 492.3623 - val_bcr: 0.4948 - val_p1: 0.0000e+00 - val_p2: 0.9896 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7051\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 512.9358 - bcr: 0.5671 - p1: 0.1564 - p2: 0.9777 - m1: 12.9333 - m2: 17.8167 - accuracy: 0.6221 - val_loss: 528.4412 - val_bcr: 0.5271 - val_p1: 1.0000 - val_p2: 0.0542 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.3462\n",
      "New best p value : 0.5310068586317327\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 318.0522 - bcr: 0.6169 - p1: 0.9169 - p2: 0.3169 - m1: 12.4000 - m2: 18.3500 - accuracy: 0.5442 - val_loss: 273.5841 - val_bcr: 0.4885 - val_p1: 0.0000e+00 - val_p2: 0.9771 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.6923\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 189.4351 - bcr: 0.6459 - p1: 0.3693 - p2: 0.9225 - m1: 13.0500 - m2: 17.7000 - accuracy: 0.6682 - val_loss: 228.9100 - val_bcr: 0.5271 - val_p1: 0.7500 - val_p2: 0.3042 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.5128\n",
      "New best p value : 0.5632198054301965\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 99.2002 - bcr: 0.7289 - p1: 0.7981 - p2: 0.6597 - m1: 12.5667 - m2: 18.1833 - accuracy: 0.7161 - val_loss: 137.4453 - val_bcr: 0.5302 - val_p1: 0.0833 - val_p2: 0.9771 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7308\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 77.6890 - bcr: 0.7539 - p1: 0.6401 - p2: 0.8677 - m1: 12.4333 - m2: 18.3167 - accuracy: 0.7917 - val_loss: 89.8702 - val_bcr: 0.6948 - val_p1: 0.6250 - val_p2: 0.7646 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7308\n",
      "New best p value : 0.7314612851724173\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 55.1673 - bcr: 0.7967 - p1: 0.6961 - p2: 0.8972 - m1: 11.8833 - m2: 18.8667 - accuracy: 0.8167 - val_loss: 87.0718 - val_bcr: 0.7219 - val_p1: 0.6250 - val_p2: 0.8188 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7564\n",
      "New best p value : 0.7624757437241537\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 34.9277 - bcr: 0.8248 - p1: 0.8514 - p2: 0.7982 - m1: 12.8333 - m2: 17.9167 - accuracy: 0.8238 - val_loss: 93.6306 - val_bcr: 0.5615 - val_p1: 0.1979 - val_p2: 0.9250 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7564\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 48.4868 - bcr: 0.8463 - p1: 0.7192 - p2: 0.9734 - m1: 13.1833 - m2: 17.5667 - accuracy: 0.8602 - val_loss: 136.2265 - val_bcr: 0.5885 - val_p1: 0.6667 - val_p2: 0.5104 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.6026\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 27.3323 - bcr: 0.8602 - p1: 0.9257 - p2: 0.7948 - m1: 12.2667 - m2: 18.4833 - accuracy: 0.8408 - val_loss: 112.6412 - val_bcr: 0.5146 - val_p1: 0.0938 - val_p2: 0.9354 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7179\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 38.4924 - bcr: 0.8548 - p1: 0.7700 - p2: 0.9395 - m1: 11.7333 - m2: 19.0167 - accuracy: 0.8866 - val_loss: 97.2383 - val_bcr: 0.6260 - val_p1: 0.6667 - val_p2: 0.5854 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.6538\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 21.9993 - bcr: 0.8342 - p1: 0.7870 - p2: 0.8813 - m1: 12.1167 - m2: 18.6333 - accuracy: 0.8413 - val_loss: 80.1601 - val_bcr: 0.6531 - val_p1: 0.6667 - val_p2: 0.6396 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.6795\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 24.4522 - bcr: 0.9022 - p1: 0.9689 - p2: 0.8355 - m1: 12.2000 - m2: 18.5500 - accuracy: 0.8793 - val_loss: 98.4747 - val_bcr: 0.5302 - val_p1: 0.1250 - val_p2: 0.9354 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7308\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 26.4842 - bcr: 0.8614 - p1: 0.7476 - p2: 0.9753 - m1: 13.3333 - m2: 17.4167 - accuracy: 0.8699 - val_loss: 131.0688 - val_bcr: 0.6094 - val_p1: 0.7188 - val_p2: 0.5000 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.6154\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 14.1434 - bcr: 0.8814 - p1: 0.9550 - p2: 0.8078 - m1: 13.3000 - m2: 17.4500 - accuracy: 0.8822 - val_loss: 71.1593 - val_bcr: 0.5646 - val_p1: 0.2396 - val_p2: 0.8896 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7436\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 13.0062 - bcr: 0.9119 - p1: 0.8339 - p2: 0.9898 - m1: 11.7500 - m2: 19.0000 - accuracy: 0.9344 - val_loss: 91.3586 - val_bcr: 0.6313 - val_p1: 0.6667 - val_p2: 0.5958 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 9.4375 - bcr: 0.9429 - p1: 0.9750 - p2: 0.9108 - m1: 11.8333 - m2: 18.9167 - accuracy: 0.9341 - val_loss: 71.9165 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "New best p value : 0.767133876300274\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 3.5364 - bcr: 0.9472 - p1: 0.9051 - p2: 0.9893 - m1: 13.2833 - m2: 17.4667 - accuracy: 0.9573 - val_loss: 73.5206 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "New best p value : 0.7699894725047896\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 132ms/step - loss: 3.2450 - bcr: 0.9597 - p1: 0.9656 - p2: 0.9539 - m1: 11.5667 - m2: 19.1833 - accuracy: 0.9594 - val_loss: 91.1391 - val_bcr: 0.6531 - val_p1: 0.6979 - val_p2: 0.6083 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.6923\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 5.6995 - bcr: 0.9644 - p1: 0.9804 - p2: 0.9484 - m1: 12.3167 - m2: 18.4333 - accuracy: 0.9573 - val_loss: 72.8991 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 3.6191 - bcr: 0.9736 - p1: 0.9589 - p2: 0.9883 - m1: 12.6500 - m2: 18.1000 - accuracy: 0.9762 - val_loss: 73.9735 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 1.3706 - bcr: 0.9883 - p1: 0.9802 - p2: 0.9964 - m1: 12.8000 - m2: 17.9500 - accuracy: 0.9910 - val_loss: 74.7647 - val_bcr: 0.7135 - val_p1: 0.6458 - val_p2: 0.7812 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7949\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 2.6119 - bcr: 0.9710 - p1: 0.9764 - p2: 0.9656 - m1: 12.2500 - m2: 18.5000 - accuracy: 0.9723 - val_loss: 75.7105 - val_bcr: 0.7073 - val_p1: 0.6458 - val_p2: 0.7688 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7821\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 2.1662 - bcr: 0.9877 - p1: 0.9876 - p2: 0.9877 - m1: 12.2667 - m2: 18.4833 - accuracy: 0.9865 - val_loss: 73.4260 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 2.2949 - bcr: 0.9815 - p1: 0.9741 - p2: 0.9889 - m1: 11.9000 - m2: 18.8500 - accuracy: 0.9823 - val_loss: 76.7496 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 1.3728 - bcr: 0.9788 - p1: 0.9849 - p2: 0.9726 - m1: 12.6667 - m2: 18.0833 - accuracy: 0.9755 - val_loss: 75.9546 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 1.5940 - bcr: 0.9732 - p1: 0.9805 - p2: 0.9658 - m1: 12.5833 - m2: 18.1667 - accuracy: 0.9721 - val_loss: 71.8883 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 133ms/step - loss: 0.8632 - bcr: 0.9870 - p1: 0.9807 - p2: 0.9933 - m1: 12.3500 - m2: 18.4000 - accuracy: 0.9894 - val_loss: 72.1505 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.9883 - bcr: 0.9889 - p1: 0.9862 - p2: 0.9917 - m1: 11.9500 - m2: 18.8000 - accuracy: 0.9886 - val_loss: 84.3695 - val_bcr: 0.6854 - val_p1: 0.6979 - val_p2: 0.6729 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7308\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 1.8921 - bcr: 0.9755 - p1: 1.0000 - p2: 0.9509 - m1: 13.1833 - m2: 17.5667 - accuracy: 0.9698 - val_loss: 72.7365 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 1.3716 - bcr: 0.9783 - p1: 0.9567 - p2: 1.0000 - m1: 13.0000 - m2: 17.7500 - accuracy: 0.9828 - val_loss: 69.3049 - val_bcr: 0.5948 - val_p1: 0.3542 - val_p2: 0.8354 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7821\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.8194 - bcr: 0.9783 - p1: 0.9632 - p2: 0.9933 - m1: 12.4833 - m2: 18.2667 - accuracy: 0.9762 - val_loss: 77.5473 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 1.0496 - bcr: 0.9870 - p1: 1.0000 - p2: 0.9740 - m1: 13.0667 - m2: 17.6833 - accuracy: 0.9830 - val_loss: 80.9472 - val_bcr: 0.6958 - val_p1: 0.6667 - val_p2: 0.7250 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7436\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.4409 - bcr: 0.9839 - p1: 0.9929 - p2: 0.9749 - m1: 11.7667 - m2: 18.9833 - accuracy: 0.9837 - val_loss: 74.9758 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.3972 - bcr: 0.9903 - p1: 0.9856 - p2: 0.9951 - m1: 12.1333 - m2: 18.6167 - accuracy: 0.9912 - val_loss: 74.0107 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.3376 - bcr: 0.9896 - p1: 0.9826 - p2: 0.9965 - m1: 12.8667 - m2: 17.8833 - accuracy: 0.9912 - val_loss: 76.1460 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.6485 - bcr: 0.9872 - p1: 0.9867 - p2: 0.9877 - m1: 12.2667 - m2: 18.4833 - accuracy: 0.9882 - val_loss: 79.3310 - val_bcr: 0.6958 - val_p1: 0.6458 - val_p2: 0.7458 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7564\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.5022 - bcr: 0.9968 - p1: 1.0000 - p2: 0.9937 - m1: 13.0833 - m2: 17.6667 - accuracy: 0.9957 - val_loss: 79.9354 - val_bcr: 0.6958 - val_p1: 0.6458 - val_p2: 0.7458 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7564\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.2928 - bcr: 0.9978 - p1: 1.0000 - p2: 0.9956 - m1: 12.6000 - m2: 18.1500 - accuracy: 0.9972 - val_loss: 78.3737 - val_bcr: 0.6958 - val_p1: 0.6458 - val_p2: 0.7458 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7564\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.6815 - bcr: 0.9919 - p1: 0.9955 - p2: 0.9883 - m1: 13.2000 - m2: 17.5500 - accuracy: 0.9908 - val_loss: 75.5064 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.1606 - bcr: 0.9977 - p1: 1.0000 - p2: 0.9954 - m1: 11.9833 - m2: 18.7667 - accuracy: 0.9972 - val_loss: 75.1497 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.3615 - bcr: 0.9852 - p1: 0.9833 - p2: 0.9870 - m1: 12.8833 - m2: 17.8667 - accuracy: 0.9851 - val_loss: 73.8376 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 134ms/step - loss: 0.3597 - bcr: 0.9861 - p1: 0.9858 - p2: 0.9863 - m1: 12.9500 - m2: 17.8000 - accuracy: 0.9870 - val_loss: 73.3323 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 135ms/step - loss: 0.2447 - bcr: 0.9885 - p1: 0.9807 - p2: 0.9962 - m1: 12.8167 - m2: 17.9333 - accuracy: 0.9880 - val_loss: 74.4150 - val_bcr: 0.7281 - val_p1: 0.6458 - val_p2: 0.8104 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7949\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 138ms/step - loss: 0.0930 - bcr: 0.9979 - p1: 1.0000 - p2: 0.9958 - m1: 12.0000 - m2: 18.7500 - accuracy: 0.9972 - val_loss: 75.5924 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.0999 - bcr: 0.9980 - p1: 1.0000 - p2: 0.9960 - m1: 12.0000 - m2: 18.7500 - accuracy: 0.9972 - val_loss: 75.4400 - val_bcr: 0.7010 - val_p1: 0.6458 - val_p2: 0.7563 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7692\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.0726 - bcr: 0.9982 - p1: 1.0000 - p2: 0.9964 - m1: 12.3500 - m2: 18.4000 - accuracy: 0.9972 - val_loss: 74.4387 - val_bcr: 0.7281 - val_p1: 0.6458 - val_p2: 0.8104 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.7949\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 0.1585 - bcr: 0.9865 - p1: 0.9847 - p2: 0.9883 - m1: 11.9333 - m2: 18.8167 - accuracy: 0.9865 - val_loss: 73.6336 - val_bcr: 0.7344 - val_p1: 0.6458 - val_p2: 0.8229 - val_m1: 5.5000 - val_m2: 14.0000 - val_accuracy: 0.8077\n",
      "Restoring model weights from the end of the best epoch. Best value : 0.770\n",
      "Epoch 00057: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    batch_size=128,\n",
    "                    epochs=200,\n",
    "                    callbacks=callbacks,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bbb787",
   "metadata": {},
   "source": [
    "Get the performance of the model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cc4ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Report for Sequential -------------------\n",
      "\n",
      "P score : 0.803\n",
      "BCR     : 0.968\n",
      "BCR hat : 0.797\n"
     ]
    }
   ],
   "source": [
    "from utils import Report\n",
    "\n",
    "report = Report(model, X_train, y_train, X_val, y_val).to_stdout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e1c0c",
   "metadata": {},
   "source": [
    "Save the csv output and model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32116fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import to_contest_csv\n",
    "\n",
    "y_test = model.predict(X_test).round().astype(np.uint8).flatten()\n",
    "\n",
    "report.to_contest_csv(f\"dnn_linear_{report.p.numpy():.3f}\", y_test, save_model=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ingi2262",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
